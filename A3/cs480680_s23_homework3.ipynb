{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81122543-63f5-4594-96fa-3daba199c15e",
   "metadata": {},
   "source": [
    "# CS480/680, Spring 2023, Assignment 3\n",
    "## Designer: Chengjie Huang; Instructor: Hongyang Zhang\n",
    "Released: June 26; Due: July 16, noon\n",
    "\n",
    "Notes:\n",
    "* Please save a copy of this notebook to avoid losing your changes.\n",
    "* Debug your code and ensure that it can run.\n",
    "* Save the output of each cell. Failure to do so may result in your coding questions not being graded.\n",
    "* To accelerate the training time, you can use Google Colab and choose 'Runtime' -> 'Change runtime type' -> 'Hardware accelerator' and set 'Hardware accelerator' to 'GPU'. This assignment may be more time-consuming, so you may need to plan ahead and leave enough time for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e09fd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (4.30.2)\n",
      "Requirement already satisfied: datasets in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (2.13.1)\n",
      "Requirement already satisfied: filelock in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from transformers) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/alex/miniconda3/envs/exp/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# In addition to numpy, pytorch, and other standard libraries, you will need the following for this assignment\n",
    "!pip install transformers datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "197c4ccf-4e0f-4c29-a326-e739bb0ce957",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1: Large Language Model (40 pts)\n",
    "Large pre-trained language models such as GPT can be useful for many natural language tasks other than text generation. In this question, we will take a look at one of such tasks: question-answering (QA).\n",
    "\n",
    "In QA task, the model is given some **context** text and a **question** related to the context. The model is tasked to generate the correct answer based on the context and question. For example, a context could be \"Joe enjoys pizza but prefers pasta over anything else\", and given a question \"What's Joe's favorite food\", the model should output \"pasta\".\n",
    "\n",
    "In this question, we will extend and fine-tune a pre-trained large language model (GPT2) to perform question-answering task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f10a5a77-1fdb-4e3f-a0dd-c1e9209c3480",
   "metadata": {},
   "source": [
    "### 1.1 SQuAD Dataset (5 pts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "178219cb-2779-437f-b1a0-6774b79fa213",
   "metadata": {},
   "source": [
    "A popular dataset for question-answering task is the Stanford Question-answering Dataset (SQuAD) ([Rajpurkar, Pranav, et al. \"Squad: 100,000+ questions for machine comprehension of text.\" arXiv preprint arXiv:1606.05250 (2016).](https://arxiv.org/abs/1606.05250)). The code below will automatically download and load the dataset. The training and validation split can be accessed with `squad_dataset['train']` and `squad_dataset['validation']` respectively.\n",
    "\n",
    "First familiarize yourself with the format of the SQuAD dataset.<br>\n",
    "In the following cells, print the size of each split as well as one example from each split in the following format:\n",
    "```\n",
    "Train/validation split: 10000 samples\n",
    "Sample id: 56de57394396321400ea2830\n",
    "Context: Joe enjoys pizza but prefers pasta over anything else\n",
    "Question: What's Joe's favorite food\n",
    "Answer: pasta\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1e73de-db8b-4cab-b23e-7557fbbb6194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/exp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset squad (/home/alex/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|██████████| 2/2 [00:00<00:00, 736.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "squad_dataset = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d3a09c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train split: 87599\n",
      "Sample id: 5733be284776f41900661182\n",
      "Context: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "Answer: Saint Bernadette Soubirous\n",
      "--------------\n",
      "Size of train split: 10570\n",
      "Sample id: 56be4db0acb8001400a502ec\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Question: Which NFL team represented the AFC at Super Bowl 50?\n",
      "Answer: Denver Broncos\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "# IMPLEMENT ME!\n",
    "train_split, val_split = squad_dataset[\"train\"], squad_dataset[\"validation\"]\n",
    "print(f\"Size of train split: {len(train_split)}\")\n",
    "print(f\"Sample id: {train_split[0]['id']}\")\n",
    "print(f\"Context: {train_split[0]['context']}\")\n",
    "print(f\"Question: {train_split[0]['question']}\")\n",
    "print(f\"Answer: {train_split[0]['answers']['text'][0]}\")\n",
    "print(\"--------------\")\n",
    "print(f\"Size of train split: {len(val_split)}\")\n",
    "print(f\"Sample id: {val_split[0]['id']}\")\n",
    "print(f\"Context: {val_split[0]['context']}\")\n",
    "print(f\"Question: {val_split[0]['question']}\")\n",
    "print(f\"Answer: {val_split[0]['answers']['text'][0]}\")\n",
    "####################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55b93436-a0f3-43dd-aa4b-80551db546a1",
   "metadata": {},
   "source": [
    "### 1.2 Extending GPT2 for question-answering task (25 pts)\n",
    "In this part, we will extend the GPT2 model to produce answers from the context based on the questions. To make use of the pre-trained GPT2 model, we will treat it as a feature extractor to compute token-wise feature vectors and add additional MLP layers to process the features for the QA task. These additional task-specific layers are sometimes called **\"adapters\"**.\n",
    "\n",
    "Use the skeleton code below and implement the following three core components:\n",
    "1. **[5 pts] Add additional MLP layer(s) to predict the location of the answer within the input.** <br>You can formulate this problem however you see fit. Below are two possible options:\n",
    "    * Classify the start and end locations of the answer. For example, given a input text of length 5 after tokenization, suppose the answer starts at token `2` and ends at token `4`, the model should predict `[0 0 1 0 0]` and `[0 0 0 0 1]` as the start and end location respectively.\n",
    "    * Directly regress the start and end locations, or the start location + length of the answer.<br><br>\n",
    "2. **[10 pts] Use the additional layer(s) to compute the location of the answer**\n",
    "3. **[10 pts] Implement task-specific loss for question-answering** <br>Depending on the approach you choose to implement (classification vs. regression), you need to use the appropriate loss.\n",
    "\n",
    "Unlike image data, text input can have varying length, which makes batch training and loss computation more challenging.\n",
    "For simplicity, you can assume the batch size is 1 in this question. I.e., the `question`, `context` and `answer` belong to a single sample in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e054aabd-32b5-42c8-88cb-8dd4cfc2107b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2TokenizerFast, GPT2Model\n",
    "\n",
    "class GPT2QuestionAnswering(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "        self.gpt2 = GPT2Model.from_pretrained('gpt2')\n",
    "        \n",
    "        ####################################################################################\n",
    "        # IMPLEMENT ME!\n",
    "        # Add additional layers for predicting the location of the answer\n",
    "        self.start_classifier = nn.Sequential(\n",
    "            nn.Linear(self.gpt2.config.n_embd, 100),\n",
    "            nn.LayerNorm(100),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(100, 1),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.end_classifier = nn.Sequential(\n",
    "            nn.Linear(self.gpt2.config.n_embd, 100),\n",
    "            nn.LayerNorm(100),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(100, 1),\n",
    "        )\n",
    "        ####################################################################################\n",
    "\n",
    "    def forward(self, question, context, answer=None):\n",
    "        question = question.strip()\n",
    "        context = context.strip()\n",
    "\n",
    "        inputs = self.tokenizer(question, context, return_tensors='pt', return_offsets_mapping=True)\n",
    "        input_ids = inputs.input_ids[:,:self.gpt2.config.n_positions]\n",
    "        attention_mask = inputs.attention_mask[:,:self.gpt2.config.n_positions]\n",
    "        if torch.cuda.is_available:\n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "        features = self.gpt2(input_ids=input_ids, attention_mask=attention_mask)['last_hidden_state']\n",
    "\n",
    "        ####################################################################################\n",
    "        # IMPLEMENT ME!\n",
    "        # Using the additional layers to compute location of the answer based on the hidden state features\n",
    "        logits_start = self.start_classifier(features)\n",
    "        logits_end = self.end_classifier(features)\n",
    "        ####################################################################################\n",
    "\n",
    "        if self.training:\n",
    "            ####################################################################################\n",
    "            # IMPLEMENT ME!\n",
    "            # In training mode, we want to return the loss based on the ground truth answer\n",
    "            # You may change the \n",
    "            \n",
    "            return self.loss(logits_start, logits_end, inputs, answer, context)\n",
    "            ####################################################################################\n",
    "        else:\n",
    "            ####################################################################################\n",
    "            # IMPLEMENT ME!\n",
    "            # In inference mode, we want to return the answer string based on the predicted start and end indices\n",
    "            answer_start_index = torch.argmax(logits_start.squeeze(-1)).item()\n",
    "            answer_end_index = torch.argmax(logits_end.squeeze(-1)).item()\n",
    "            ####################################################################################\n",
    "            return self.tokenizer.decode(inputs.input_ids[0, answer_start_index : answer_end_index + 1]).strip()\n",
    "\n",
    "    \n",
    "    ####################################################################################\n",
    "    # IMPLEMENT ME!\n",
    "    def loss(self, logits_start, logits_end, inputs, answer, context):\n",
    "        # Compute the loss based on the answers\n",
    "        # Tip1: If you choose the classification approach, then you need the start and end locations\n",
    "        #       of the answer within the **tokenized** input as your classification target.\n",
    "        #       You may need to use inputs.offset_mapping from the input tokenization.\n",
    "        #       See https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.__call__.return_offsets_mapping\n",
    "        # Tip2: If you choose the regression approach, then you can use answer['answer_start']\n",
    "        #       and length of the answer as your regression target.\n",
    "        proper_answer = answer[\"text\"][0]\n",
    "        start_idx = answer[\"answer_start\"][0]\n",
    "        end_idx = start_idx + len(proper_answer)\n",
    "\n",
    "        if context[start_idx-1:end_idx-1] == proper_answer:\n",
    "            start_idx = start_idx - 1\n",
    "            end_idx = end_idx -1 \n",
    "        elif context[start_idx - 2: end_idx - 2] == proper_answer:\n",
    "            start_idx = start_idx - 2\n",
    "            end_idx = end_idx - 2\n",
    "\n",
    "        start_token_idx = inputs.char_to_token(0, char_index=start_idx, sequence_index=1)\n",
    "        end_token_idx = inputs.char_to_token(0, char_index=end_idx, sequence_index=1)\n",
    "\n",
    "        if (start_token_idx is None or start_token_idx < 0 or start_token_idx >= self.gpt2.config.n_positions):\n",
    "            start_token_idx = 0 # start of sequence\n",
    "        if (end_token_idx is None or end_token_idx < 0 or end_token_idx >= self.gpt2.config.n_positions):\n",
    "            end_token_idx = len(inputs.input_ids[0]) - 1 # end of sequence\n",
    "           \n",
    "        x = torch.zeros((1, len(inputs.input_ids[0]), 1)).cuda()\n",
    "        y = torch.zeros((1, len(inputs.input_ids[0]), 1)).cuda()\n",
    "        x[0, start_token_idx, 0] = 1\n",
    "        y[0, end_token_idx, 0] = 1\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        return (loss(logits_start, x) + loss(logits_end, y)) / 2\n",
    "    ####################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b1cbf58-fd50-4264-8f55-a3cd43d9d353",
   "metadata": {},
   "source": [
    "We can evaluate the pre-trained model's performance on the validation split. Since the model has not been adapted to the question-answering task yet, and additional untrained layers have been added, we expect the model to perform poorly.\n",
    "\n",
    "In question-answering task, we use two evaluation metrics:\n",
    "* **Exact match**: the percentage of predictions that match the ground truth answer exactly\n",
    "* **F1 score**: the average overlap (in terms of tokens) between the prediction and ground truth answer\n",
    "\n",
    "Higher values are better for both metrics. For reference, humans can achieve 77.0% exact match and 86.8% F1 score, while SOTA method achieves 90% exact match and over 95% F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17f71c98-258a-46f3-bbd6-53b17ea4e6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, metric):\n",
    "    from tqdm.autonotebook import tqdm\n",
    "    model = model.eval()\n",
    "    preds = []\n",
    "    for idx, data in enumerate(tqdm(dataset['validation'])):\n",
    "        preds.append(dict(id=data['id'], prediction_text=model(data['question'], data['context'], data['answers'])))\n",
    "    references = [dict(answers=data['answers'], id=data['id']) for data in dataset['validation']]\n",
    "    return metric.compute(predictions=preds, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a9a2ef-dfee-4b74-9cb1-d890020b2139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10047/1889257040.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  squad_metric = load_metric('squad')\n",
      "100%|██████████| 10570/10570 [01:35<00:00, 110.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.02838221381267739, 'f1': 4.5409993675323}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "squad_metric = load_metric('squad')\n",
    "model = GPT2QuestionAnswering()\n",
    "if torch.cuda.is_available:\n",
    "    model = model.cuda()\n",
    "\n",
    "evaluate(model, squad_dataset, squad_metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27911c9c-d884-409c-8f6c-4dfa37c19bba",
   "metadata": {},
   "source": [
    "### 1.3 Fine-tuning GPT2 on Squad (10 pts)\n",
    "To adapt a pre-trained model to a specific downstream task (in this case the question-answering task), a common technique is to **\"fine-tune\"** the model. Fine-tuning simply means training the model using task-specific data, typically with shorter epochs and smaller learning rates. Certain part of the model (e.g., pre-trained layers or early layers) can also be frozen, meaning the weights are not updated during training.\n",
    "\n",
    "In this part, we will fine-tune the model on SQuAD dataset.<br>\n",
    "In the cell below, implement the training loop and record the loss values in a list to be plotted later.\n",
    "\n",
    "**Note:** due to the size of the model and dataset, it is not required to train for too many iterations since this question will not be graded purely based on the performance of your model.\n",
    "\n",
    "##### Optional Objectives\n",
    "* **Freezing GPT2 Layers:** Depending on the additional layers you added to the network in the previous part, you may choose to freeze the pre-trained GPT2 layers during fine-tuning. In PyTorch, this can be achieved by setting `requires_grad=False` for the layers of interest. You are encouraged to try both and note your observations.\n",
    "* **Gradient Accumulation:** The model from previous question is not suitable for batch training, which could increase the stochasiticy of the training process and make convergence slower. One way to circumvent this problem is via gradient accumulation, wherein the gradient is accumulated for multiple iterations before the weights are updated, which increases the effective batch size. In PyTorch, this can be implemented by accumulating the loss and performing `zero_grad()` and `step()` every few iterations instead of every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a518b645-df0b-4a4f-8308-def9e94dc4eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7771/87599 [04:22<46:09, 28.82it/s, loss=1.09] "
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "losses = []\n",
    "\n",
    "####################################################################################\n",
    "# IMPLEMENT ME!\n",
    "num_epochs = 3\n",
    "\n",
    "accum_steps = 5\n",
    "####################################################################################\n",
    "\n",
    "model = model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
    "for e in range(num_epochs):\n",
    "    # Shuffle dataset in each epoch\n",
    "    indices = torch.randperm(len(squad_dataset[\"train\"])).tolist()\n",
    "\n",
    "    # tqdm gives you a nice little progress bar\n",
    "    pbar = tqdm(indices)\n",
    "    for i, idx in enumerate(pbar):\n",
    "        # Obtain data from training split\n",
    "        data = squad_dataset['train'][idx]\n",
    "\n",
    "        ####################################################################################\n",
    "        # IMPLEMENT ME!\n",
    "        loss = model(question=data[\"question\"], context=data[\"context\"], answer=data[\"answers\"]) / accum_steps\n",
    "        loss.backward()\n",
    "        if i % accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        ####################################################################################\n",
    "\n",
    "        # Record loss values\n",
    "        losses.append(loss.item())\n",
    "        pbar.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df9ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.forward(question=data[\"question\"], context=data[\"context\"], answer=data[\"answers\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdb2c7ff",
   "metadata": {},
   "source": [
    "Plot the loss values over the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa4770f-a581-4bbe-8cf1-c9f5ac746295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=90)\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7def8913",
   "metadata": {},
   "source": [
    "Evaluate the model performance after fine-tuning. You should see a much higher score compared to the previous results.\n",
    "\n",
    "**Note:** this question will not be graded based on the performance of your model. However, together with the code and the loss plot in the previous parts, the performance will be used to judge if the fine-tuning is implemented properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30489235-e642-412e-a366-16000e15c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, squad_dataset, squad_metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5081a3dd",
   "metadata": {},
   "source": [
    "Try the model using your own text and question. Can it give you the correct answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b541e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model('How many world cups has Pele won?', 'Pele has won 3 world cups.', {\"text\": [\"3\"], \"answer_start\": [13]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb98bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer('How many world cups has Pele won?', 'Pele has won 3 world cups.', return_tensors='pt', return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2eca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer.decode(torch.tensor([513]))\n",
    "'Pele has won 3 world cups.'.index(\"3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd40a4bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2: GAN (60 pts)\n",
    "In this question, you will be designing and training a GAN for image generation.\n",
    "\n",
    "Training a GAN for image generation can be computationally demanding. Luckily, MNIST dataset provides 28x28 images of handwritten digits, allowing a GAN to be trained more quickly. Below are some examples from the digits dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a033f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist = MNIST(root='.', download=True)\n",
    "images = np.stack([data[0] for data in mnist]).astype(np.float32)\n",
    "images = images / 128 - 1    # normalize between -1 and 1\n",
    "plt.figure(dpi=90)\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(images[np.random.choice(len(images))])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95181643",
   "metadata": {},
   "source": [
    "**Note:** You are allowed to use other **publicly available** image datasets for this question. If you choose to do so, please include the link to the dataset you use, and replace the cell above to visualize examples from your dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f35a59f",
   "metadata": {},
   "source": [
    "### 2.1 Generator and Discriminator (20 pts)\n",
    "In this part, you need to implement a generator and discriminator model using the skeleton code below. Recall that\n",
    "* The **generator** takes a randomly sampled noise $z$ as input and outputs an image with the same size as the dataset\n",
    "* The **discriminator** takes an image as input and performs a binary classification\n",
    "\n",
    "In this case, both the generator and discriminator should be convolutional neural networks (CNNs). You may not use a pretrained network, but other design decisions such as the depth and width of the network are up to you.\n",
    "\n",
    "Depending on the resources available to you, you may choose to implement a small network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72903174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ####################################################################################\n",
    "        # IMPLEMENT ME!\n",
    "        raise NotImplementedError\n",
    "        ####################################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ####################################################################################\n",
    "        # IMPLEMENT ME!\n",
    "        raise NotImplementedError\n",
    "        ####################################################################################\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ####################################################################################\n",
    "        # IMPLEMENT ME!\n",
    "        raise NotImplementedError\n",
    "        ####################################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ####################################################################################\n",
    "        # IMPLEMENT ME!\n",
    "        raise NotImplementedError\n",
    "        ####################################################################################\n",
    "\n",
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "if torch.cuda.is_available:\n",
    "    gen = gen.cuda()\n",
    "    disc = disc.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cf520b9",
   "metadata": {},
   "source": [
    "### 2.2 Generate image samples from generator (10 pts)\n",
    "\n",
    "During the training and inference, the generator needs to generate batch of images from random noise.\n",
    "Implement the generation function below.\n",
    "\n",
    "**Note:** This function will later be used in training, therefore you need to be careful and avoid cutting off the gradient accidentally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f010904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(model, num_samples):\n",
    "    ####################################################################################\n",
    "    # IMPLEMENT ME!\n",
    "    # The shape of the returned samples should be [num_samples, H, W]\n",
    "    raise NotImplementedError\n",
    "    ####################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4491bbb",
   "metadata": {},
   "source": [
    "Without any training, the samples generated by the generator does not resemble any digit in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.eval()\n",
    "samples = generate_samples(gen, 25).detach().cpu().numpy()\n",
    "plt.figure(dpi=90)\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(samples[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5597cba0",
   "metadata": {},
   "source": [
    "### 2.3 GAN training algorithm (25 pts)\n",
    "In this part, you will implement the GAN training algorithm, which involves alternating the training of discriminator and generator.\n",
    "\n",
    "**Note:** You may start with the standard GAN loss ([Goodfellow, Ian, et al. \"Generative adversarial networks.\" Communications of the ACM 63.11 (2020): 139-144.](https://arxiv.org/abs/1406.2661)). If you have extra time and resources, you can explore other GAN formulations that either improves convergence or alleviates the mode-collapse problem. For instance, LSGAN ([Mao, Xudong, et al. \"Least squares generative adversarial networks.\" Proceedings of the IEEE international conference on computer vision. 2017.](https://arxiv.org/abs/1611.04076)) and Wasserstein GAN ([Arjovsky, Martin, Soumith Chintala, and Léon Bottou. \"Wasserstein generative adversarial networks.\" International conference on machine learning. PMLR, 2017.](http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf)) are both great options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4561303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gen, disc, images, num_epochs, batch_size):\n",
    "    from tqdm.autonotebook import tqdm\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    losses_gen = []\n",
    "    losses_disc = []\n",
    "\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "    loader = DataLoader(images, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    ####################################################################################\n",
    "    # IMPLEMENT ME!\n",
    "\n",
    "    # 1. [5 pts] Build optimizer for each model and choose an appropriate learning rate\n",
    "    #    You may specify different optimizers or learning rates for generator and discrminator\n",
    "    #    to balance the training loss and avoid one model overpowering the other.\n",
    "    #    Ideally we would like to reach an equilibrium between the generator and discriminator.\n",
    "    optimizer_gen = ...\n",
    "    optimizer_disc = ...\n",
    "\n",
    "    pbar = tqdm(range(num_epochs))\n",
    "    for e in pbar:\n",
    "        for i, data_real in enumerate(loader):\n",
    "            if torch.cuda.is_available:\n",
    "                data_real = data_real.cuda()\n",
    "\n",
    "            # 2. Update discriminator\n",
    "            # 2.1. Unfreeze discriminator\n",
    "            disc.train()\n",
    "            disc.requires_grad_(True)\n",
    "\n",
    "            # 2.2. [5 pts] Construct inputs and training labels for discriminator\n",
    "            #      The discriminator training should use both real and fake samples\n",
    "            #      Tip: since we do not want to update the generator, the fake samples\n",
    "            #           need to be detached from the computation graph. You can use\n",
    "            #           detach().clone() for this operation.\n",
    "            inputs_disc = ...\n",
    "            labels_disc = ...\n",
    "            if torch.cuda.is_available:\n",
    "                inputs_disc = inputs_disc.cuda()\n",
    "                labels_disc = labels_disc.cuda()\n",
    "\n",
    "            # 2.4. [5 pts] Discrminator training \n",
    "            #      This should include loss computation and weight updates\n",
    "            #      You can choose implement standard GAN, LSGAN, or Wasserstein gan loss\n",
    "            loss_disc = ...\n",
    "            losses_disc.append(loss_disc.item())\n",
    "\n",
    "            # 3. Update generator\n",
    "            # 3.1. Freeze discriminator\n",
    "            disc.eval()\n",
    "            disc.requires_grad_(False)\n",
    "\n",
    "            # 3.2. [5 pts] Construct input and training labels for the generator\n",
    "            #      The generator training only uses fake samples, since in this step\n",
    "            #      only the generator will be updated.\n",
    "            #      The training labels should be different from the discriminator\n",
    "            #      labels since we want to optimize the generator in the opposite\n",
    "            #      gradient direction in order to \"fool\" the discriminator.\n",
    "            inputs_gen = ...\n",
    "            labels_gen = ...\n",
    "            if torch.cuda.is_available:\n",
    "                inputs_gen = inputs_gen.cuda()\n",
    "                labels_gen = labels_gen.cuda()\n",
    "\n",
    "            # 3.4. [5 pts] Generator training\n",
    "            #      This should include loss computation and weight updates\n",
    "            #      You can choose implement standard GAN, LSGAN, or Wasserstein gan loss\n",
    "            loss_gen = ...\n",
    "            losses_gen.append(loss_gen.item())\n",
    "    ####################################################################################\n",
    "\n",
    "            pbar.set_postfix(loss_gen=losses_gen[-1], loss_disc=losses_disc[-1])\n",
    "    return losses_gen, losses_disc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "157a8f5a",
   "metadata": {},
   "source": [
    "You may change the number of epochs and batch size based on the time and resources available to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = ...\n",
    "batch_size = ...\n",
    "losses_gen, losses_disc = train_gan(gen, disc, images, num_epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5711080",
   "metadata": {},
   "source": [
    "### 2.4 Observations and Analysis (5 pts)\n",
    "\n",
    "**[2.5 pts]** Use the code below to plot the losses for the generator and discriminator. Do you see any problem with the training process?<br> Do you think your GAN has converged? Why and why not?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af69544",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=90)\n",
    "plt.plot(losses_disc, label='Dicriminator')\n",
    "plt.plot(losses_gen, label='Generator')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d39408d5",
   "metadata": {},
   "source": [
    "**[2.5 pts]** Use the code below to visualize some images generated by your GAN. Do you see any problem with the samples generated by your GAN?<br> Do you think your GAN has mode collapse problem? Why and why not?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33952441",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.eval()\n",
    "samples = generate_samples(gen, 25).detach().cpu().numpy()\n",
    "plt.figure(dpi=90)\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(samples[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
