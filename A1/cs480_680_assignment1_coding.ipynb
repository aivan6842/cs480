{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2dYlHWRAA1a"
      },
      "source": [
        "# CS 480/680 assignment 1 (coding part)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuEDzbbiAcXo"
      },
      "source": [
        "- Please save a copy of this notebook to avoid losing your changes.\n",
        "- Debug your code and ensure that it can run before submission.\n",
        "- Save the output of each cell. Failure to do so may result in your coding questions not being graded.\n",
        "- Submit your completed version of this notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu7upEwVALqo"
      },
      "source": [
        "## Question 1-2\n",
        "\n",
        "In this question, you are asked to implement the perceptron algorithm on the Spambase dataset. Please refer to the [dataset webpage](https://archive.ics.uci.edu/ml/datasets/spambase) for details on the dataset, and consult the lecture slides and suggested readings for details on the perceptron algorithm.\n",
        "\n",
        "- Please note that `is_spam` is the label of the dataset. The labellings are 0/1 instead of -1/1 (which was used for the perceptron covered in class).\n",
        "- Recording the accuracy after every step may be costly, therefore you can instead record the accuracy every $x$ steps, where $x$ can be 100, 1000, your training set size, 4601 (the size of the dataset), or any other value you find appropriate.\n",
        "- It is recommended that you split the dataset into training/validation/testing datasets, but we will not deduct marks if you don't.\n",
        "- You will get full marks for \n",
        "    - Correct implementation of the perceptron algorithm\n",
        "    - An accuracy (on the validation dataset, if you splitted the dataset) vs number of training steps plot that relects the progress of the training\n",
        "    - Final reported accuracy (on the testing dataset, if you splitted the dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gl0lxf-V-LYF"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "# TODO: add any other package you need\n",
        "\n",
        "# Download the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\n",
        "filename = 'spambase.csv'\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# Load the dataset into a Pandas dataframe\n",
        "column_names = [\n",
        "    'word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
        "    'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet',\n",
        "    'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will',\n",
        "    'word_freq_people', 'word_freq_report', 'word_freq_addresses',\n",
        "    'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you',\n",
        "    'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000',\n",
        "    'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n",
        "    'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n",
        "    'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
        "    'word_freq_technology', 'word_freq_1999', 'word_freq_parts',\n",
        "    'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n",
        "    'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
        "    'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;',\n",
        "    'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$',\n",
        "    'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest',\n",
        "    'capital_run_length_total', 'is_spam'\n",
        "]\n",
        "data = pd.read_csv(filename, names=column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# random shuffle of data\n",
        "seed = 0\n",
        "np.random.seed(seed=seed)\n",
        "\n",
        "data_shuffled = data.iloc[np.random.permutation(len(data))]\n",
        "data = data_shuffled.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# perceptron uses +1, -1 instead of 0, 1. So well convert 0 to -1\n",
        "data.loc[data[\"is_spam\"] == 0, \"is_spam\"] = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split dataset into training, validation, testing\n",
        "train_split_pct, val_split_pct = 0.8, 0.1\n",
        "num_train_ex, num_val_ex = int(len(data) * train_split_pct), int(len(data) * val_split_pct)\n",
        "\n",
        "train_idx = num_train_ex\n",
        "val_idx = num_train_ex + num_val_ex\n",
        "\n",
        "train_data, val_data, test_data = data[:train_idx], data[train_idx:val_idx], data[val_idx:]\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "val_data = val_data.reset_index(drop=True)\n",
        "test_data = test_data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_acc(dataset, w, b):\n",
        "    correct = 0\n",
        "    for i in range(len(dataset)):\n",
        "        x = dataset.loc[i, dataset.columns != \"is_spam\"].values\n",
        "        y = dataset.iloc[i][\"is_spam\"]\n",
        "\n",
        "        if np.sign(y) == np.sign(np.dot(w, x) + b):\n",
        "            correct += 1\n",
        "    \n",
        "    return correct / len(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xJ6Xw9T-CHQg"
      },
      "outputs": [],
      "source": [
        "# TODO: your implementation\n",
        "def perceptron_train(train_dataset, val_dataset, epochs = 1000, report_each=100):\n",
        "    #init params\n",
        "    w = [0] * (train_dataset.shape[1] - 1) # b/c target is not included\n",
        "    b = 0\n",
        "    validation_accs = []\n",
        "    training_accs = []\n",
        "\n",
        "    target = \"is_spam\"\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(epoch)\n",
        "        for index in range(len(train_dataset)):\n",
        "            # get random index\n",
        "            #index = np.random.randint(0, len(train_dataset))\n",
        "\n",
        "            y = train_dataset.iloc[index][target]\n",
        "            x = train_dataset.loc[index, train_dataset.columns != target].values\n",
        "            \n",
        "            if y * (np.dot(x, w) + b) <= 0:\n",
        "                w = w + y*x\n",
        "                b = b + y\n",
        "            \n",
        "            if index % report_each == 0:\n",
        "                training_accs.append(calculate_acc(train_dataset, w, b))\n",
        "                validation_accs.append(calculate_acc(val_dataset, w, b))\n",
        "        \n",
        "    return w, b, training_accs, validation_accs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "report_each = 1000\n",
        "w, b, train_accs, val_accs = perceptron_train(train_dataset=train_data, val_dataset=val_data, epochs=epochs, report_each=report_each)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot training acc\n",
        "plt.plot([i for i in range(len(train_accs))], train_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot([i for i in range(len(val_accs))], val_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy2lir66C2AJ"
      },
      "outputs": [],
      "source": [
        "# TODO: plot the accuracy against the number of steps\n",
        "# TODO: report the final accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Test data accuracy: {calculate_acc(test_data, w, b)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
